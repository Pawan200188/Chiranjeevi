# Chiranjeevi ‚Äî Brain Tumor Detection

**üìù Project Description**
--------------------------

**Chiranjeevi ‚Äî Brain Tumor Detection** is a deep learning‚Äìbased system designed to detect and classify brain tumors from MRI scans with high accuracy. The project leverages **state-of-the-art CNN architectures** such as **VGG16, ResNet18, ResNet50, MobileNetV2, and YOLOv8** to identify tumors and, in some cases, localize them in real time.

The dataset, sourced from **Kaggle**, consists of **3,264 annotated MRI images**, augmented to **7,023 images** to enhance variability and generalization. Preprocessing steps such as resizing, normalization, and augmentation were applied to prepare the data for robust training and testing.

Among all models tested, **VGG16 achieved the highest classification accuracy of 97.79%**, while **YOLOv8 demonstrated strong real-time detection and localization capabilities**, making the system both accurate and clinically practical. The project also explores lightweight architectures like **MobileNetV2** to ensure usability in **resource-constrained healthcare environments**.

For deployment, the system integrates a **Streamlit-based frontend** with a **Flask API backend**, allowing users to upload MRI scans and instantly receive diagnostic outputs such as tumor type (glioma, meningioma, pituitary tumor, or no tumor) and visual heatmaps for localization.

This project highlights the potential of **AI-assisted diagnostics** to:

*   Support radiologists in early detection,
    
*   Improve surgical planning through precise tumor localization,
    
*   Enhance accessibility in low-resource healthcare centers, and
    
*   Serve as an educational and research tool for advancing medical AI.

üìë Table of Contents
--------------------

1.  **Introduction to Brain Tumor Detection**
    
2.  **Demo of the Project**
    
3.  **Impact of Early Brain Tumor Diagnosis**
    
4.  **Project Objectives**
    
5.  **Project Pipeline / System Architecture**
    
6.  **Data Collection & Pre-processing Workflow**
    
7.  **Model Training & Prediction Workflow**
    
8.  **Deep Learning Models Used & Their Architecture**
    
9.  **Evaluation Metrics & Results**
    
10.  **Code Running Commands / How to Run**
    
11.  **Technologies & Frameworks Used**
    
12.  **Real-Time Applications & Use Cases**
    
13.  **Limitations & Future Scope**
    
14.  **Conclusion**
    
15.  **Team Members & Guide**

üß† Introduction to Brain Tumor Detection
----------------------------------------

Brain tumors represent one of the most complex and life-threatening neurological conditions, with their **diverse types, varying locations, and complex biological behavior**. Early and accurate detection plays a critical role in improving patient survival rates, enabling timely intervention, and reducing the risk of severe complications such as paralysis, cognitive decline, or even mortality.

Traditional diagnostic methods, such as **Magnetic Resonance Imaging (MRI)** and **Computed Tomography (CT) scans**, while highly valuable, are often subject to **human interpretation and variability**. This reliance on radiologists may introduce **subjectivity, longer diagnostic times, and potential delays in treatment**.

With the rapid advancements in **Artificial Intelligence (AI)** and **Deep Learning (DL)**, particularly **Convolutional Neural Networks (CNNs)**, there is immense potential to transform neuroimaging workflows. Deep learning models can automatically learn **discriminative features from MRI scans**, classify tumor types, and even localize tumor regions with high accuracy.

The **Chiranjeevi ‚Äì Brain Tumor Detection Project** integrates **state-of-the-art CNN architectures** (VGG16, ResNet, MobileNetV2, YOLOv8) with a **web-based deployment platform**. This system is designed not only to achieve high accuracy in classification but also to enable **real-time tumor detection and visualization**, making it a valuable tool in both **clinical settings** and **low-resource healthcare environments**.

Ultimately, this project demonstrates how **AI-assisted diagnostics** can complement radiologists, enhance surgical planning, and expand accessibility of advanced medical tools, driving significant improvements in patient care and medical research.

## Demo of the Project

üåç Impact of Early Brain Tumor Diagnosis
----------------------------------------

Early detection of brain tumors has a profound impact on **patient outcomes, healthcare efficiency, and medical decision-making**. The integration of **AI-driven diagnostic systems** like this project directly addresses challenges in traditional radiology by providing **fast, reliable, and accessible results**.

### üîë Key Impacts

1.  **Improved Survival Rates**
    
    *   Detecting tumors at an early stage allows for **timely treatment interventions** such as surgery, chemotherapy, or radiotherapy.
        
    *   This can significantly enhance survival rates and overall quality of life.
        
2.  **Prevention of Severe Outcomes**
    
    *   Early diagnosis reduces risks of irreversible complications like **paralysis, memory loss, cognitive impairment, or vision problems**.
        
    *   Patients benefit from more effective treatment planning before the tumor reaches an advanced stage.
        
3.  **Assistance in Low-Resource Settings**
    
    *   AI-based detection reduces dependency on **specialized radiologists**, making diagnostic tools available in **rural or under-equipped healthcare centers**.
        
    *   Lightweight models like **MobileNetV2** can be deployed on low-end systems, expanding accessibility.
        
4.  **Enhanced Surgical Planning**
    
    *   Models like **YOLOv8** enable **real-time tumor localization**, guiding neurosurgeons in planning minimally invasive and precise surgeries.
        
    *   This reduces post-operative risks and improves patient recovery.
        
5.  **Healthcare Efficiency**
    
    *   Automated detection saves radiologists significant time by **pre-screening scans** and highlighting areas of concern.
        
    *   Medical practitioners can focus more on patient care rather than lengthy image interpretation.
        
6.  **Educational and Research Advancement**
    
    *   Serves as a valuable tool for training medical professionals in AI-assisted diagnostics.
        
    *   Provides a scalable framework to expand AI research into other neurological conditions (e.g., Alzheimer‚Äôs, stroke).

üéØ Project Objectives
---------------------

The **Chiranjeevi ‚Äì Brain Tumor Detection Project** was designed with the aim of leveraging **deep learning** to improve the accuracy, speed, and accessibility of brain tumor diagnosis. The following objectives guided the development of the system:

1.  **Early Detection of Brain Tumors**
    
    *   Develop a robust deep learning pipeline capable of identifying brain tumors at an early stage from MRI scans, improving patient survival and treatment outcomes.
        
2.  **High Accuracy and Reliability**
    
    *   Train and evaluate multiple **state-of-the-art CNN architectures** (VGG16, ResNet18, ResNet50, YOLOv8, MobileNetV2) to achieve accuracy comparable to expert radiologists.
        
    *   Ensure robustness by using a diverse and augmented dataset.
        
3.  **Comprehensive Evaluation Metrics**
    
    *   Assess models using a broad range of metrics:
        
        *   **Training & Validation Accuracy**
            
        *   **Precision, Recall, and F1-Score**
            
        *   **Confusion Matrices**
            
        *   **Validation Loss Trends**
            
    *   Go beyond simple accuracy to ensure **clinical applicability**.
        
4.  **Model Optimization for Clinical Use**
    
    *   Optimize training with techniques such as **data augmentation, early stopping, dynamic learning rate scheduling**, and lightweight architectures for deployment in **resource-constrained environments**.
        
5.  **Practical Deployment**
    
    *   Build a **Streamlit-based user interface** and a **Flask API backend** to create a user-friendly system for doctors and healthcare workers.
        
    *   Enable **real-time predictions** with visual outputs like tumor heatmaps and bounding boxes.
        
6.  **Support for Healthcare & Research**
    
    *   Provide assistance in **low-resource healthcare centers** by reducing reliance on expert radiologists.
        
    *   Serve as a **research and educational tool** to explore the role of AI in medical imaging and extend applications to related neurological conditions.

üîÑ Project Pipeline / System Architecture
-----------------------------------------

The **Chiranjeevi ‚Äì Brain Tumor Detection system** follows a structured pipeline that ensures smooth transition from **raw MRI images** to **real-time tumor classification and localization**.

### üìå Workflow Steps

1.  **Input & Data Preprocessing**
    
    *   Collect MRI images from the Kaggle dataset.
        
    *   Resize, normalize, and augment images to improve model generalization.
        
    *   Split into **training (70%)**, **validation (20%)**, and **testing (10%)** sets.
        
2.  **Model Training**
    
    *   Train multiple **deep learning architectures** (VGG16, ResNet18, ResNet50, YOLOv8, MobileNetV2).
        
    *   Use **Adam optimizer**, **cross-entropy loss**, and **dynamic learning rate scheduling**.
        
    *   Monitor training and validation metrics to avoid overfitting.
        
3.  **Evaluation**
    
    *   Assess models using **Accuracy, Precision, Recall, F1-score, Loss curves, and Confusion Matrices**.
        
    *   Identify the best-performing models (VGG16 for classification, YOLOv8 for localization).
        
4.  **Deployment**
    
    *   Integrate the trained models into a **Streamlit-based web UI**.
        
    *   Connect backend via **Flask/Django API** for serving predictions.
        
    *   Provide real-time results: tumor type (glioma, meningioma, pituitary, no tumor) + heatmaps.
        
5.  **Output & Clinical Use**
    
    *   Return visual overlays and classification reports to assist radiologists.
        
    *   Enable usage in **clinical, educational, and low-resource healthcare environments**.

üìÇ Data Collection & Pre-processing Workflow
--------------------------------------------

A well-prepared dataset is the foundation of any robust AI model. For this project, MRI images of brain tumors were collected, cleaned, and pre-processed to ensure consistency and better generalization during training.

### üóÇÔ∏è Data Collection

*   **Source:** Publicly available **Kaggle Brain MRI Dataset**
    
*   **Size:** 3,264 annotated MRI images
    
*   **Classes:**
    
    *   Glioma
        
    *   Meningioma
        
    *   Pituitary Tumor
        
    *   No Tumor
        
*   **Augmentation:** Dataset size increased to **7,023 images** using augmentation techniques.
    

### ‚öôÔ∏è Pre-processing Steps

1.  **Resizing**
    
    *   All MRI images were resized to a **fixed input size** (e.g., 224√ó224) for model compatibility.
        
2.  **Normalization**
    
    *   Pixel values scaled to the **\[0,1\] range** for computational efficiency.
        
3.  **Data Augmentation**
    
    *   Applied transformations to improve dataset variability and reduce overfitting:
        
        *   Rotation
            
        *   Zooming
            
        *   Flipping (horizontal/vertical)
            
        *   Shifting & contrast adjustments
            
4.  **Dataset Splitting**
    
    *   To ensure unbiased model evaluation, data was divided into:
        
        *   **Training set:** 70%
            
        *   **Validation set:** 20%
            
        *   **Testing set:** 10%
     

ü§ñ Model Training & Prediction Workflow
---------------------------------------

The **Chiranjeevi ‚Äì Brain Tumor Detection system** employs **deep learning models** trained on preprocessed MRI scans to classify tumors and, in some cases, localize them. This workflow covers both **training** (offline) and **prediction** (real-time inference).

### üèãÔ∏è Model Training Workflow

1.  **Input Preprocessed Data**
    
    *   Preprocessed images (resized, normalized, augmented) are fed into CNN-based architectures.
        
2.  **Feature Extraction**
    
    *   CNN layers extract features such as **edges, textures, tumor shape, and size**.
        
    *   Deeper layers capture **high-level representations** for classification.
        
3.  **Training Setup**
    
    *   **Models Used:** VGG16, ResNet18, ResNet50, MobileNetV2, YOLOv8
        
    *   **Optimizer:** Adam
        
    *   **Loss Function:** Cross-Entropy Loss
        
    *   **Frameworks:** TensorFlow 2.11, PyTorch 2.5.1
        
    *   **Hardware:** GPU acceleration (NVIDIA CUDA recommended)
        
    *   **Techniques:**
        
        *   Early stopping to avoid overfitting
            
        *   Dynamic learning rate scheduler for faster convergence
            
4.  **Monitoring Metrics**
    
    *   **Training Loss & Validation Loss** to detect over/underfitting
        
    *   **Accuracy Trends** to measure model performance
        
    *   **Precision, Recall, F1-score, Confusion Matrix** for clinical reliability
        
5.  **Model Selection**
    
    *   **VGG16:** Best classification accuracy (**97.79%**)
        
    *   **YOLOv8:** Best for **real-time localization**
        
    *   **MobileNetV2:** Balanced accuracy + efficiency for resource-constrained systems

<img width="1641" height="919" alt="{3959CF64-761E-4D69-B0BF-74C341562DDE}" src="https://github.com/user-attachments/assets/55440a70-3ca7-466e-8423-af8ee2cc019b" />


### üîÆ Prediction Workflow

Once trained, the model is integrated into the **Streamlit-based UI** for real-time predictions:

1.  **Input MRI Scan**
    
    *   User uploads an MRI image through the web interface.
        
2.  **Preprocessing**
    
    *   Image resized & normalized for compatibility with trained models.
        
3.  **Model Inference**
    
    *   The image is passed through the **selected model** (e.g., VGG16 or YOLOv8).
        
    *   **Output:**
        
        *   Classification ‚Üí Glioma, Meningioma, Pituitary Tumor, or No Tumor
            
        *   Localization ‚Üí Bounding box / heatmap highlighting tumor regions
            
4.  **Result Generation**
    
    *   Diagnostic results returned to the user in both **visual** (overlay/heatmap) and **textual** form.
        
5.  **Clinical Use**
    
    *   Results can be exported or shared with doctors for further medical decision-making.

üß© Deep Learning Models Used & Their Architecture
-------------------------------------------------

To ensure high accuracy and efficiency, this project leverages multiple **state-of-the-art Convolutional Neural Network (CNN) architectures**. Each model offers unique strengths for **classification** and **localization** of brain tumors.

### 1Ô∏è‚É£ **VGG16**

*   **Architecture:**
    
    *   16 layers deep (13 convolutional layers + 3 fully connected layers).
        
    *   Uses **3√ó3 convolution filters** and max-pooling layers.
        
    *   Simple, uniform structure ‚Üí effective feature extraction.
        
*   **Strength:**
    
    *   Achieved the **highest classification accuracy (97.79%)**.
        
    *   Excellent for medical imaging tasks where **fine-grained details matter**.
        
*   **Limitations:**
    
    *   Computationally heavy compared to lightweight models.
        

### 2Ô∏è‚É£ **ResNet18 & ResNet50**

*   **Architecture:**
    
    *   Introduces **Residual Connections (skip connections)** to solve vanishing gradient problems.
        
    *   ResNet18 ‚Üí shallower (fewer layers), ResNet50 ‚Üí deeper with more feature extraction power.
        
*   **Strength:**
    
    *   Learns more complex features compared to plain CNNs.
        
    *   Generalizes well with deeper architectures.
        
*   **Performance:**
    
    *   **ResNet18** performed decently (validation accuracy ~89%).
        
    *   **ResNet50** showed instability and lower performance on this dataset.
        

### 3Ô∏è‚É£ **MobileNetV2**

*   **Architecture:**
    
    *   Uses **depthwise separable convolutions** for computational efficiency.
        
    *   Includes **inverted residual blocks** and **linear bottlenecks**.
        
*   **Strength:**
    
    *   Designed for **mobile and low-resource environments**.
        
    *   Achieved good accuracy (~93.5%) with much **lower computational demand**.
        
*   **Use Case:**
    
    *   Ideal for deployment in **rural/under-equipped healthcare centers**.
        

### 4Ô∏è‚É£ **YOLOv8 (You Only Look Once v8)**

*   **Architecture:**
    
    *   Real-time **object detection model** with convolutional backbone + detection head.
        
    *   Outputs **bounding boxes & confidence scores** for localized regions.
        
*   **Strength:**
    
    *   Enables **real-time tumor localization** in MRI scans.
        
    *   Supports precise bounding-box detection + heatmap visualization.
        
*   **Performance:**
    
    *   Strong results on localization tasks, with mAP50 ‚âà 83% after 50 epochs.
        
*   **Use Case:**
    
    *   Best suited for **real-time surgical planning** and **instant diagnosis**.

üìä Evaluation Metrics & Results
-------------------------------

Evaluating medical AI models requires more than just accuracy. Since diagnostic systems directly affect patient outcomes, a **comprehensive set of metrics** was used to assess reliability, robustness, and clinical applicability.

### ‚öôÔ∏è Evaluation Metrics

1.  **Accuracy** ‚Äì Overall proportion of correctly classified images.
    
2.  **Precision** ‚Äì Ability of the model to minimize **false positives** (misdiagnosing a healthy brain as having a tumor).
    
3.  **Recall (Sensitivity)** ‚Äì Ability to detect **true positives** (catching actual tumors, crucial in medicine).
    
4.  **F1-Score** ‚Äì Harmonic mean of Precision and Recall, balancing false positives & false negatives.
    
5.  **Validation Loss** ‚Äì Tracks overfitting/underfitting during training.
    
6.  **Confusion Matrix** ‚Äì Category-wise performance visualization.
    
7.  **mAP (Mean Average Precision)** ‚Äì Used for **YOLOv8 localization tasks**.
    

### üìå Key Results

#### üîπ **VGG16 (Best Classifier)**

*   **Validation Accuracy:** 97.79%
    
*   **Validation Loss:** ~64.3 after 20 epochs
    
*   **Strength:** Most stable and reliable for classification tasks.
    
*   **Observation:** Consistent improvement with epochs, excellent generalization.
    

#### üîπ **ResNet18**

*   **Validation Accuracy:** ~89.2% after 50 epochs
    
*   **Validation Loss:** ~83.2
    
*   **Strength:** Better feature extraction than shallow CNNs.
    
*   **Observation:** Moderate performance; slight overfitting noted.
    

#### üîπ **ResNet50**

*   **Validation Accuracy:** ~66% (unstable)
    
*   **Validation Loss:** fluctuated heavily (e.g., -1949% to -9117%)
    
*   **Observation:** Struggled with dataset ‚Üí poor generalization.
    

#### üîπ **MobileNetV2**

*   **Validation Accuracy:** ~93.5%
    
*   **Validation Loss:** ~16.8 at best epoch
    
*   **Strength:** Lightweight model for resource-constrained setups.
    
*   **Observation:** Balanced trade-off between speed and accuracy.
    

#### üîπ **YOLOv8 (Localization Model)**

*   **Metrics after 50 epochs:**
    
    *   Precision (Box P): ~82%
        
    *   Recall (Box R): ~74%
        
    *   mAP50: ~83.1%
        
    *   mAP50-95: ~65.9%
        
*   **Strength:** Effective **real-time tumor localization** with bounding boxes.
    
*   **Observation:** Best suited for surgical planning and instant diagnosis.
    

### üìà Performance Trends

*   **Training Accuracy & Loss:**
    
    *   Training accuracy steadily improved with epochs.
        
    *   Training loss consistently decreased ‚Üí effective learning.
        
*   **Validation Accuracy & Loss:**
    
    *   VGG16 showed stable validation accuracy across epochs.
        
    *   YOLOv8 steadily improved detection metrics (Precision/Recall).
        
*   **Error Analysis:**
    
    *   Occasional **false negatives** in small/unclear tumor regions.
        
    *   Noisy MRI scans reduced performance ‚Üí mitigated with preprocessing/denoising.
        

### üèÜ Final Deployment Models

*   **VGG16** ‚Üí Deployed for **highly accurate classification** of tumor types.
    
*   **YOLOv8** ‚Üí Deployed for **real-time localization** and diagnostic visualization.

üåç Real-Time Applications & Use Cases
-------------------------------------

The **Chiranjeevi ‚Äì Brain Tumor Detection Project** is designed not just as a research prototype but as a **practically deployable solution** that can directly impact healthcare.

### üîπ 1. Early Diagnosis of Brain Tumors

*   **Rapid Detection:** Real-time analysis of MRI scans using YOLOv8 enables **instant tumor identification**.
    
*   **Improved Survival:** Early detection reduces the risk of severe complications such as **paralysis, cognitive disabilities, or mortality**.
    

### üîπ 2. Assistance in Low-Resource Healthcare

*   **AI-Powered Diagnostics:** Reduces reliance on expert radiologists in **rural or under-equipped hospitals**.
    
*   **Efficient Workflow:** Automates tumor detection so doctors can focus on **treatment and patient care**.
    
*   **Lightweight Models:** MobileNetV2 ensures deployment even in **resource-constrained environments**.
    

### üîπ 3. Enhanced Surgical Planning

*   **Precise Localization:** YOLOv8 provides bounding boxes/heatmaps to highlight **exact tumor regions**.
    
*   **Support for Neurosurgeons:** Assists in **minimally invasive procedures** by identifying tumor shape, size, and position.
    
*   **3D Visualization Integration:** Can be extended for advanced surgical planning with MRI/CT-based 3D imaging.
    

### üîπ 4. Research & Educational Tool

*   **Training for Medical Professionals:** Helps radiologists and surgeons learn AI-assisted diagnostic techniques.
    
*   **AI Research Expansion:** Framework can be adapted for other conditions such as **Alzheimer‚Äôs, stroke, or lung cancer detection**.
    
*   **Benchmarking Tool:** Provides performance comparisons of popular deep learning models (VGG16, ResNet, MobileNetV2, YOLOv8).
    

### üîπ 5. Patient-Centric Benefits

*   **Faster Diagnosis:** Reduces waiting time for results.
    
*   **Accessible Reports:** Generates both **visual heatmaps** and **textual reports**.
    
*   **Cost Efficiency:** Makes advanced diagnostic support available at **lower cost**, especially in underserved areas.
    

‚ú® These real-time applications highlight the project‚Äôs potential to **bridge the gap between AI research and clinical practice**, making brain tumor detection **faster, more reliable, and more accessible worldwide**.

‚ö†Ô∏è Limitations & Future Scope
-----------------------------

While the **Chiranjeevi ‚Äì Brain Tumor Detection Project** shows promising results, certain limitations exist that must be addressed for **real-world clinical adoption**.

### üîª Current Limitations

1.  **Dataset Constraints**
    
    *   Dataset sourced primarily from **Kaggle**; lacks diversity across hospitals, demographics, and MRI machine types.
        
    *   Limited real-world variability (e.g., noise, artifacts, rare tumor subtypes).
        
2.  **Evaluation Metrics**
    
    *   Current focus on accuracy and loss, while **sensitivity, specificity, and AUC-ROC** are more clinically relevant.
        
3.  **Computational Requirements**
    
    *   High-performance GPUs are required for training models like VGG16 and YOLOv8, limiting accessibility in resource-poor hospitals.
        
4.  **Clinical Applicability Gaps**
    
    *   Regulatory compliance, ethical approval, and integration with hospital information systems remain unexplored.
        
    *   The system does not yet incorporate **patient history, symptoms, or multimodal data**.
        
5.  **Model Limitations**
    
    *   **ResNet50** showed unstable performance on this dataset.
        
    *   Small/unclear tumors sometimes lead to **false negatives**.
        

### üöÄ Future Scope

1.  **Dataset Expansion**
    
    *   Incorporate **multi-institutional datasets** for higher generalization.
        
    *   Include **DICOM/NIfTI formats** for direct clinical integration.
        
2.  **Advanced Architectures**
    
    *   Explore **Attention U-Net, Vision Transformers (ViT), and Hybrid CNN-Transformer models** for better segmentation and explainability.
        
    *   Implement **Explainable AI (XAI)** tools such as Grad-CAM and LIME for transparent predictions.
        
3.  **Lightweight Deployments**
    
    *   Optimize models through **quantization, pruning, and knowledge distillation** for real-time inference on mobile devices and embedded systems.
        
4.  **Integration with Clinical Systems**
    
    *   Build support for **HL7 / DICOM standards** to integrate with PACS (Picture Archiving and Communication Systems) in hospitals.
        
    *   Add **EHR (Electronic Health Record) integration** for patient-centric analysis.
        
5.  **Enhanced Evaluation**
    
    *   Use clinically important metrics such as **Sensitivity, Specificity, and ROC curves**.
        
    *   Conduct **prospective clinical trials** to validate real-world performance.
        
6.  **Extended Applications**
    
    *   Adapt framework for detection of other neurological and medical conditions such as **stroke, Alzheimer‚Äôs, and lung tumors**.
        
    *   Expand into **3D tumor segmentation** for surgical planning.
        

‚ú® By addressing these limitations and expanding scope, this project can evolve from a **research prototype** into a **clinically reliable AI-powered diagnostic assistant**.

‚úÖ Conclusion
------------

The **Chiranjeevi ‚Äì Brain Tumor Detection Project** demonstrates the potential of **deep learning** in revolutionizing medical imaging by providing a reliable, efficient, and accessible tool for **brain tumor classification and localization**.

By leveraging advanced architectures such as **VGG16, ResNet, MobileNetV2, and YOLOv8**, the system achieves:

*   **High accuracy (97.79% with VGG16)** for tumor classification.
    
*   **Real-time localization (YOLOv8)** to support surgical planning and diagnosis.
    
*   **Lightweight deployment (MobileNetV2)** for low-resource healthcare environments.
    

The integration of a **Streamlit-based web interface** with a **Flask API backend** ensures a **user-friendly and practical deployment**, making the solution accessible to radiologists, neurosurgeons, and even under-equipped medical centers.

While certain challenges remain‚Äîsuch as dataset diversity, clinical validation, and regulatory approval‚Äîthis project lays the groundwork for **AI-assisted diagnostics** in neurology. With future improvements in **explainability, dataset expansion, and clinical integration**, such systems could become essential in advancing diagnostic capabilities, **improving patient outcomes, and saving lives**.

## Team
    @Poras2005
    @SnehalDnyane

